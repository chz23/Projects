{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0890c5-c493-41e7-8276-33eef54bd1cd",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 2: Data Analysis of HDB Housing Prices in Singapore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ad241-fbde-4a45-bc48-7d8ec1175c57",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Modelling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa4c3c-2ecb-4ecf-9cdf-1687d5b6737c",
   "metadata": {},
   "source": [
    "## Contents\n",
    "---\n",
    "- [Overview of Modelling](##Overview-of-Modelling)\n",
    "- [Linear, Ridge & LASSO Regression](##Linear,-Ridge-&-LASSO-Regression)\n",
    "- [Predictions & Submissions](##Predictions-&-Submissions)\n",
    "- [Model Evaluations](Model-Evaluations-(Kaggle))\n",
    "- [Interpretation of Coefficients & Insights](##Interpretation-of-Coefficients-&-Insights)\n",
    "- [Recommendations & Conclusion](##Recommendations-&-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8707f32-fe91-455c-92c5-8e68576aede8",
   "metadata": {},
   "source": [
    "---\n",
    "## Overview of Modelling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8e9aa-c10f-47ff-a19f-521457bbedaa",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "Following the features selection process, a total of 14 features were shortlisted for modelling:\n",
    "\n",
    "| Feature | Type | Description | No. Labels (Categorical) | Unit of Measurement |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| `flat_type` | Categorical | Flat type of resale flat. | 7 | - |\n",
    "| `flat_model` | Categorical | Flat model of resale flat. | 20 | - |\n",
    "| `Tranc_Year` | Categorical | Year that the resale flat was transacted. | 10 | - |\n",
    "| `planning_area` | Categorical | Planning area that resale flat is located in. | 32 | - |\n",
    "| `bus_interchange` | Categorical | boolean value denoting if the resale flat's nearest MRT station has a bus interchange. | 2 | - |\n",
    "| `mrt_interchange` | Categorical | boolean value denoting if the resale flat's nearest MRT station is an MRT interchange.  | 2 | - |\n",
    "| `floor_area_sqm` | Numerical | Floor area of the resale flat. | - | squared metres ($m^2$) |\n",
    "| `mid` | Numerical | Middle value of the range of levels that the resale flat is located in; used as an approximation of its level. | - | - |\n",
    "| `max_floor_lvl` | Numerical | Number of levels in the resale flat's block. | - | - |\n",
    "| `Mall_Nearest_Distance` | Numerical | Distance from the resale flat to the nearest mall. | - | metres (m) |\n",
    "| `Mall_Within_500m` | Numerical | Number of malls within 500m of the resale flat. | - | - |\n",
    "| `Hawker_Nearest_Distance` | Numerical | Distance from the resale flat to the nearest hawker centre. | - | metres (m) |\n",
    "| `mrt_nearest_distance` | Numerical | Distance from the resale flat to the nearest MRT station. | - | metres (m) |\n",
    "| `hdb_age_at_tranc` | Numerical | Age of the resale flat as at transaction. | - | years |\n",
    "\n",
    "### Split of Data\n",
    "\n",
    "Two separate DataFrames will be created for the purposes of modelling two different 'profiles' of housing:\n",
    "- `trn_high` for high-end resale flats\n",
    "- `trn_reg` for the remaining, 'regular' resale flats\n",
    "\n",
    "The basis of separation will be `planning_area`. Specifically, `trn_high` will only include the following planning areas:\n",
    "- `Tanglin`\n",
    "- `Outram`\n",
    "- `Bukit Timah`\n",
    "\n",
    "### Modelling Process\n",
    "\n",
    "Prior to modelling, preprocessing will be done:\n",
    "- scale the numerical features\n",
    "- one-hot encode the categorical features\n",
    "\n",
    "Three types of models will be used:\n",
    "- Linear regression (`LinearRegression`)\n",
    "- Ridge (L2) regression (`RidgeCV`)\n",
    "- LASSO (L1) regression (`LassoCV`)\n",
    "\n",
    "\n",
    "Following this, predictions for `test.csv` will be generated and submitted to Kaggle, which will then return the RMSE scores by model.\n",
    "\n",
    "The models will then be individually evaluated based on the following:\n",
    "- $R^2$ score (only for `train.csv`)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "\n",
    "### Interpretations, Insights, Recommendations & Conclusion\n",
    "\n",
    "The second-last segement of this notebook will cover interpretations of the coefficients, as well as insights that can be made from them.\n",
    "\n",
    "To conclude, recommendations will be given based on everything that has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd93ce-801d-48c2-9258-67c913241fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfafa81c-00c8-4267-bccc-cca6afd02e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train.csv and drop the unnecessary column.\n",
    "# This will be used to generate the model.\n",
    "\n",
    "trn = pd.read_csv('../data/train_cleaned.csv')\n",
    "trn.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784e6bf0-adbc-435d-90ac-9556bc2e1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test.csv and drop the unnecessary column.\n",
    "# This will be what predictions are generated on.\n",
    "\n",
    "tst = pd.read_csv('../data/test_cleaned.csv')\n",
    "tst.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c74c996-fa8b-4dc5-ae6f-0228e4acccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split trn by planning areas.\n",
    "\n",
    "trn_high = trn[(trn.planning_area == 'Tanglin') | \\\n",
    "               (trn.planning_area == 'Outram') | \\\n",
    "               (trn.planning_area == 'Bukit Timah')]\n",
    "\n",
    "trn_reg = trn.drop(trn_high.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cce02fa-fae5-47a7-ac35-f812881f5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split trn by planning areas.\n",
    "\n",
    "tst_high = tst[(tst.planning_area == 'Tanglin') | \\\n",
    "               (tst.planning_area == 'Outram') | \\\n",
    "               (tst.planning_area == 'Bukit Timah')]\n",
    "\n",
    "tst_reg = tst.drop(tst_high.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57830957-f63f-47ee-a523-89f4c3ccc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features into numerical and categorical.\n",
    "\n",
    "numerical_cols = ['floor_area_sqm',\n",
    "                  'mid',\n",
    "                  'max_floor_lvl',\n",
    "                  'Mall_Nearest_Distance',\n",
    "                  'Mall_Within_500m', \n",
    "                  'Hawker_Nearest_Distance',\n",
    "                  'mrt_nearest_distance',\n",
    "                  'hdb_age_at_tranc']\n",
    "\n",
    "categorical_cols = ['flat_type',\n",
    "                    'flat_model',\n",
    "                    'Tranc_Year',\n",
    "                    'planning_area',\n",
    "                    'mrt_interchange', \n",
    "                    'bus_interchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4575eb43-758a-4d80-9e57-35c021102bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes in a DataFrame, preprocesses it, and generates the model specified.\n",
    "\n",
    "def lr_l1_l2_cv(model_type=None, df=None, test_size=0.2, random_state=42):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_type: str\n",
    "        Possible values: 'lr', 'l1', 'l2'\n",
    "    df: pd.DataFrame\n",
    "        DataFrame to be used in function.\n",
    "    test_size: float\n",
    "        Value must be between 0.0 and 1.0. Represents the proportion\n",
    "        of the dataset to include in the test split.\n",
    "    random_state: int\n",
    "        From sklearn: \n",
    "        \"Controls the shuffling applied to the data before applying the split.\"\n",
    "    '''\n",
    "    \n",
    "    # Drop the dependent variable.\n",
    "    X = df.drop('resale_price', axis=1)\n",
    "    y = df['resale_price']\n",
    "    \n",
    "    # Split training data into training and testing sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state, \n",
    "                                                        stratify=None)\n",
    "    \n",
    "    # Scale numerical variables before modelling.\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train[numerical_cols])\n",
    "    X_train_ss = ss.transform(X_train[numerical_cols])\n",
    "    X_test_ss = ss.transform(X_test[numerical_cols])\n",
    "    \n",
    "    # One-hot encode categorical variables before modelling.\n",
    "    ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "    ohe.fit(X_train[categorical_cols])\n",
    "    X_train_ohe = ohe.transform(X_train[categorical_cols])\n",
    "    X_test_ohe = ohe.transform(X_test[categorical_cols])\n",
    "    \n",
    "    # Merge the scaled numerical features with one-hot encoded categorical features.\n",
    "    X_train_processed = np.concatenate([X_train_ss, X_train_ohe], axis=1)\n",
    "    X_test_processed = np.concatenate([X_test_ss, X_test_ohe], axis=1)\n",
    "    \n",
    "    # Apply the specified model.\n",
    "    if model_type == 'lr':\n",
    "        model = LinearRegression()\n",
    " \n",
    "    elif model_type == 'l1':       \n",
    "        model = LassoCV(n_alphas=100, cv=5)\n",
    "\n",
    "    elif model_type == 'l2':     \n",
    "        model = RidgeCV(alphas=np.logspace(0, 5, 100), cv=5)\n",
    "    \n",
    "    # Fit the model.\n",
    "    model.fit(X_train_processed, y_train)\n",
    "        \n",
    "    # Returns the following in the form of a list:\n",
    "    # Model\n",
    "    # Training score\n",
    "    # Test score\n",
    "    # List of features used\n",
    "    return [model, \n",
    "            model.score(X_train_processed, y_train), \n",
    "            model.score(X_test_processed, y_test), \n",
    "            list(ss.get_feature_names_out(numerical_cols))+list(ohe.get_feature_names_out(categorical_cols))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de760a9e-668d-48c7-8124-06a6f5f27de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain readable coefficients from a given model.\n",
    "\n",
    "def get_coefs_df(models_list=None):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_list: list\n",
    "        List of models to pass into the function.\n",
    "    '''\n",
    "    \n",
    "    # Extract coefficients from the models.\n",
    "    coefs = [int(models_list[i][0].coef_[x]) \\\n",
    "             for x in range(len(models_list[0][0].coef_)) \\\n",
    "             for i in range(len(models_list))]\n",
    "    \n",
    "    # Group coefficients with respective features together for readibility.\n",
    "    coefs_dict = {feature: lst for feature, lst in zip(models_list[0][-1], \n",
    "                                                       [coefs[i:i+3] for i in range(0, len(coefs), 3)])}\n",
    "\n",
    "    # Store the above as a DataFrame.\n",
    "    df_coefs = pd.DataFrame.from_dict(coefs_dict,\n",
    "                                      orient='index',\n",
    "                                      columns=['lr', 'ridge', 'lasso'])\n",
    "    \n",
    "    return df_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd4f9ab-7d20-4cb7-8667-c67fcf2e231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process unseen data before generating predictions.\n",
    "\n",
    "def process_features(df=None):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame to be used in function.\n",
    "    '''\n",
    "    \n",
    "    # Create a copy of the DataFrame.\n",
    "    X = df.copy()\n",
    "    \n",
    "    # Scale numerical variables before modelling.\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X[numerical_cols])\n",
    "    X_ss = ss.transform(X[numerical_cols])\n",
    "    \n",
    "    # One-hot encode categorical variables before modelling.\n",
    "    ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "    ohe.fit(X[categorical_cols])\n",
    "    X_ohe = ohe.transform(X[categorical_cols])\n",
    "    \n",
    "    # Merge the scaled numerical features with one-hot encoded categorical features.\n",
    "    X_processed = np.concatenate([X_ss, X_ohe], axis=1)\n",
    "        \n",
    "    return X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07563e3c-4db8-4f85-b76f-051f814becc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate predictions for unseen data.\n",
    "\n",
    "def df_preds(test=None, train=None, model=None):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    test: pd.DataFrame\n",
    "        Generated from test.csv\n",
    "    train: pd.DataFrame\n",
    "        Generated from train.csv.\n",
    "    model: LinearRegression(), RidgeCV(), or LassoCV()\n",
    "        Trained model to fit the data on.\n",
    "    '''\n",
    "    \n",
    "    # Merge the test and train DataFrames.\n",
    "    # This is done to avoid inevitable errors such as missing features from the test data.\n",
    "    test_train = pd.concat([test, train.drop(['resale_price'], axis=1)])\n",
    "    \n",
    "    # Process the merged dataset.\n",
    "    test_train_processed = process_features(df=test_train)\n",
    "    \n",
    "    # Generate predictions for the merged dataset.\n",
    "    test_train_preds = model[0].predict(test_train_processed)\n",
    "    \n",
    "    # Create a DataFrame to store only the test predictions.\n",
    "    test_train_df = pd.DataFrame.from_dict(\n",
    "        {i: [id_tst, pred] for i, id_tst, pred in zip(range(test.shape[0]), test.id.values, test_train_preds)}, \n",
    "        orient='index', \n",
    "        columns=['Id', 'Predicted'])\n",
    "    \n",
    "    return test_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef89a6b1-6db4-468c-98bd-3c7c6f83abdb",
   "metadata": {},
   "source": [
    "---\n",
    "## Linear, Ridge & LASSO Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72dedd9d-6da9-4739-b5a2-f21ae5e69534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model for the high-end flats.\n",
    "\n",
    "lr_high = lr_l1_l2_cv(model_type='lr', df=trn_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd824317-02f0-41b7-b087-d9df777e029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model for the regular flats.\n",
    "\n",
    "lr_reg = lr_l1_l2_cv(model_type='lr', df=trn_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c553aaf-1150-479e-89b4-bf5e49880319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ridge regression model for the high-end flats.\n",
    "\n",
    "ridge_high = lr_l1_l2_cv(model_type='l2', df=trn_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a21b41-b35c-4c2f-8d59-d0ae29b45f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ridge regression model for the regular flats.\n",
    "\n",
    "ridge_reg = lr_l1_l2_cv(model_type='l2', df=trn_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc573cb2-e6c8-495d-875c-1d4477d1c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LASSO regression model for the high-end flats.\n",
    "\n",
    "lasso_high = lr_l1_l2_cv(model_type='l1', df=trn_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbd59971-24f5-46be-8f9b-71a92e8462d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LASSO regression model for the regular flats.\n",
    "\n",
    "lasso_reg = lr_l1_l2_cv(model_type='l1', df=trn_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47a9617a-fec9-49c8-a61f-299349c8573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of results of lr_l1_l2_cv function.\n",
    "\n",
    "models = [lr_high, ridge_high, lasso_high, lr_reg, ridge_reg, lasso_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b2593b2-5051-402d-b9a6-6aa50ffbf317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of R2 scores.\n",
    "\n",
    "r2 = pd.DataFrame.from_dict({model_str: model[1:3] for model, model_str in zip(\n",
    "    models, [f'{i}_{x}' for i, x in zip(\n",
    "        ['linear', 'ridge', 'lasso']*2, ['high' for i in range(3)]+['reg' for i in range(3)])])}, \n",
    "                            orient='index', \n",
    "                            columns=['train_score', 'test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "addb24e0-16fb-4416-8006-f4e17334a0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_high</th>\n",
       "      <td>0.964471</td>\n",
       "      <td>0.961154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_high</th>\n",
       "      <td>0.962265</td>\n",
       "      <td>0.962085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_high</th>\n",
       "      <td>0.961868</td>\n",
       "      <td>0.961210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_reg</th>\n",
       "      <td>0.888787</td>\n",
       "      <td>0.886844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_reg</th>\n",
       "      <td>0.888780</td>\n",
       "      <td>0.886850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_reg</th>\n",
       "      <td>0.884783</td>\n",
       "      <td>0.883021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_score  test_score\n",
       "linear_high     0.964471    0.961154\n",
       "ridge_high      0.962265    0.962085\n",
       "lasso_high      0.961868    0.961210\n",
       "linear_reg      0.888787    0.886844\n",
       "ridge_reg       0.888780    0.886850\n",
       "lasso_reg       0.884783    0.883021"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b20902a-f8a3-45a6-8f72-db20a66eb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of RMSE values.\n",
    "\n",
    "rmse = pd.DataFrame.from_dict({model_str: sqrt(mean_squared_error(df.resale_price.values, \n",
    "                                                                  model[0].predict(process_features(df=df)))) \\\n",
    "                               for df, model, model_str in zip(\n",
    "    [trn_high for i in range(3)]+[trn_reg for i in range(3)],\n",
    "    models,\n",
    "    [f'{i}_{x}' for i, x in zip(\n",
    "        ['linear', 'ridge', 'lasso']*2, ['high' for i in range(3)]+['reg' for i in range(3)])])},\n",
    "                             orient='index',\n",
    "                             columns=['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "317f7725-2540-4f23-884e-9a4e3e24be1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_high</th>\n",
       "      <td>46451.923524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_high</th>\n",
       "      <td>47460.829789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_high</th>\n",
       "      <td>47759.780075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_reg</th>\n",
       "      <td>46985.170699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_reg</th>\n",
       "      <td>46986.120480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_reg</th>\n",
       "      <td>47813.207680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rmse\n",
       "linear_high  46451.923524\n",
       "ridge_high   47460.829789\n",
       "lasso_high   47759.780075\n",
       "linear_reg   46985.170699\n",
       "ridge_reg    46986.120480\n",
       "lasso_reg    47813.207680"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b045b-d703-4b50-a953-b416ca0cd740",
   "metadata": {},
   "source": [
    "---\n",
    "## Predictions & Submissions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02ecf887-9299-45fb-847a-637ebab0c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file to store the predictions for submission to Kaggle.\n",
    "\n",
    "# for model_high, model_reg, model_str in zip(\n",
    "#     [lr_high, ridge_high, lasso_high], \n",
    "#     [lr_reg, ridge_reg, lasso_reg], \n",
    "#     ['linear', 'ridge', 'lasso']\n",
    "# ):\n",
    "    \n",
    "#     pd.concat(\n",
    "#         [df_preds(test=tst_high, train=trn_high, model=model_high), df_preds(test=tst_reg, train=trn_reg, model=model_reg)]\n",
    "#     ).to_csv(f'../data/submission_{model_str}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e341c32-4565-4fca-857b-e12e7e8075d4",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Evaluations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3506c94b-c242-4175-ae64-68d69d7fdf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65902\\AppData\\Local\\Temp\\ipykernel_13664\\2274569391.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  rmse.append(pd.DataFrame.from_dict({'kaggle_linear': 47_235.40188,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_high</th>\n",
       "      <td>46451.923524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_reg</th>\n",
       "      <td>46985.170699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_reg</th>\n",
       "      <td>46986.120480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaggle_ridge</th>\n",
       "      <td>47227.320150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaggle_linear</th>\n",
       "      <td>47235.401880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_high</th>\n",
       "      <td>47460.829789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_high</th>\n",
       "      <td>47759.780075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_reg</th>\n",
       "      <td>47813.207680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaggle_lasso</th>\n",
       "      <td>48014.337380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       rmse\n",
       "linear_high    46451.923524\n",
       "linear_reg     46985.170699\n",
       "ridge_reg      46986.120480\n",
       "kaggle_ridge   47227.320150\n",
       "kaggle_linear  47235.401880\n",
       "ridge_high     47460.829789\n",
       "lasso_high     47759.780075\n",
       "lasso_reg      47813.207680\n",
       "kaggle_lasso   48014.337380"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Including Kaggle RMSE values into rmse.\n",
    "# The relevant image can be viewed in the kaggle_submissions folder.\n",
    "\n",
    "rmse.append(pd.DataFrame.from_dict({'kaggle_linear': 47_235.40188,\n",
    "                                     'kaggle_ridge': 47_227.32015,\n",
    "                                     'kaggle_lasso': 48_014.33738}, \n",
    "                                     orient='index', \n",
    "                                     columns=['rmse'])).sort_values('rmse', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d2b53c5-1ada-4cf7-8f9d-8bcbf589b918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ridge_high</th>\n",
       "      <td>0.962265</td>\n",
       "      <td>0.962085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_high</th>\n",
       "      <td>0.961868</td>\n",
       "      <td>0.961210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_high</th>\n",
       "      <td>0.964471</td>\n",
       "      <td>0.961154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_reg</th>\n",
       "      <td>0.888780</td>\n",
       "      <td>0.886850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_reg</th>\n",
       "      <td>0.888787</td>\n",
       "      <td>0.886844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso_reg</th>\n",
       "      <td>0.884783</td>\n",
       "      <td>0.883021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train_score  test_score\n",
       "ridge_high      0.962265    0.962085\n",
       "lasso_high      0.961868    0.961210\n",
       "linear_high     0.964471    0.961154\n",
       "ridge_reg       0.888780    0.886850\n",
       "linear_reg      0.888787    0.886844\n",
       "lasso_reg       0.884783    0.883021"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.sort_values('test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff7f21-5854-4da3-8abb-7a30b8012a36",
   "metadata": {},
   "source": [
    "#### $R^2$ scores\n",
    "\n",
    "There's little variation across all the models for their respective datasets. However, there is a rather marked difference between the $R^2$ scores of the high-end models vs the regular models, with the former performing much better. A score of 0.96 means 96% of the variance in resale price can be explained by the chosen features - this means that the features selected for this model were very useful in predicting resale prices, at least for the given datasets, and that they were indeed statistically significant. \n",
    "\n",
    "For the regular models, all of them topped out at around 0.88. This performance, while not as impressive as the high-end model, does still mean that the model was able to account for 88% of the variance in resale price given the features. It does, however, mean that predicting prices for the average resale flats is actually a lot more complicated, which isn't that surprising. \n",
    "\n",
    "The size of the population is much larger for the regular model as opposed to the high-end model. Amongst the high-end flats, there are actually pretty standard patterns to be seen that was covered earlier on in the EDA. For example, all Pinnacle@Duxton flats are pretty similar to one another. It's much easier for the model to 'learn' about the specific traits of particular groups of observations. This is of course a lot harder for the regular model, which reflects the decision-making process of a huge and extremely varied lot of people - your everyday people. Naturally, it will be more difficult to predict values accurately.\n",
    "\n",
    "#### RMSE values\n",
    "\n",
    "RMSE values are where we actually get to test the model on unseen data. They represent the average difference between actual and predicted values. This is an absolute value, rather than a proportion or a percentage, so it's not quite possible to say if it can be further lowered, or how \"good\" a value you've obtained. However, we can still draw some conclusions.\n",
    "\n",
    "Firstly, having similar values across board does indicate that the model managed to avoid overfitting. Secondly, this is a value that can be easily interpreted. Having an RMSE value of around 47K means that, on average, the predictions differ from the actual values by 47K. Whether or not this is an acceptable value is honestly up to the individual. Someone with the means and willingness to purchase a high-end flat may not be particularly bothered by this. They could possibly accept the model (\"Good enough!\") and call it a day. On the other hand, someone who is more price-sensitive and potentially looking for flats that are much more inexpensive might see this as an issue. The difference doesn't just lie in the fact that the former has more cash to spare than the latter - it's also a matter of proportion. $47K could be a merely 3%-5% of what the wealthier person is willing to fork out, but it may be between 10% - 15% of what the other person's budget.\n",
    "\n",
    "#### Selected Model\n",
    "\n",
    "Based on the above, the better-performing models underwent either linear or ridge regression. The difference between the 2 models is rather slight. The most significant difference is between the RMSE values for linear and ridge, when calculated based on the training data, with the former have a lower value. Therefore, the **linear model** will be picked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f1b46-04e4-4a69-9708-9102f17efda9",
   "metadata": {},
   "source": [
    "---\n",
    "## Interpretations of Coefficients & Insights\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b4a68e70-e6af-4352-8366-1b04947755b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mall_Within_500m</th>\n",
       "      <td>247708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mall_Nearest_Distance</th>\n",
       "      <td>223774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawker_Nearest_Distance</th>\n",
       "      <td>209398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrt_nearest_distance</th>\n",
       "      <td>205410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <td>59015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_4 ROOM</th>\n",
       "      <td>57998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>28272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_3 ROOM</th>\n",
       "      <td>22188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdb_age_at_tranc</th>\n",
       "      <td>21316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_floor_lvl</th>\n",
       "      <td>-4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_5 ROOM</th>\n",
       "      <td>-5255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             lr\n",
       "Mall_Within_500m         247708\n",
       "Mall_Nearest_Distance    223774\n",
       "Hawker_Nearest_Distance  209398\n",
       "mrt_nearest_distance     205410\n",
       "floor_area_sqm            59015\n",
       "flat_type_4 ROOM          57998\n",
       "mid                       28272\n",
       "flat_type_3 ROOM          22188\n",
       "hdb_age_at_tranc          21316\n",
       "max_floor_lvl             -4055\n",
       "flat_type_5 ROOM          -5255"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain coefficients for high-end model.\n",
    "\n",
    "get_coefs_df(models_list=[lr_high])[['lr']].sort_values('lr', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd2fc9-39ec-4b03-bf3c-3897e42461cd",
   "metadata": {},
   "source": [
    "### High-End Model\n",
    "\n",
    "This model was built was flats located in Tanglin, Outram and Bukit Timah. According to the coefficients, there were 4 particularly important features: `Mall_Within_500m`, `Mall_Nearest_Distance`, `Hawker_Nearest_Distance`, `mrt_nearest_distance`. \n",
    "\n",
    "The malls do seem _awfully_ important. But when we consider where these flats are actually located, the reason for these coefficients may become a little clearer. The malls closest to flats in these areas are likely to be part of Orchard Road, which is infamously expensive to live in. The feature at the top of the list measures how many malls there are within 500m of the flat, which means the numbers for this feature actually run very small. If the number for this is high, given where these flats are located, it probably means that they are living _very_ close to the most expensive areas in Singapore! Thus, it's no wonder that a single unit increase in this feature can cause resale price to soar by a whooping $247K.\n",
    "\n",
    "Some of these results are quite counterintuitive - it seems like the older the HDB flat, the more expensive it is - for every additional year, flat price increases by $21K. The average age of flats in these areas is around 26 years. This could well just be a case of people prioritising flat size over age, especially since there are technically still many years left on the lease. That said, the coefficient, given that it's housing prices and specifically for the most expensive areas, is not worryingly large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a54e9b83-a0e3-42f5-8fc5-e86a8dcddebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flat_type_4 ROOM</th>\n",
       "      <td>409476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Apartment</th>\n",
       "      <td>203541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Improved-Maisonette</th>\n",
       "      <td>200425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrt_nearest_distance</th>\n",
       "      <td>172242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_DBSS</th>\n",
       "      <td>159726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdb_age_at_tranc</th>\n",
       "      <td>93345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <td>87200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_3 ROOM</th>\n",
       "      <td>81353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mall_Within_500m</th>\n",
       "      <td>37708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_MULTI-GENERATION</th>\n",
       "      <td>17025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawker_Nearest_Distance</th>\n",
       "      <td>13770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mall_Nearest_Distance</th>\n",
       "      <td>11448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Multi Generation</th>\n",
       "      <td>5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_2 ROOM</th>\n",
       "      <td>-3524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>-4088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_5 ROOM</th>\n",
       "      <td>-24054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_floor_lvl</th>\n",
       "      <td>-24329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_type_EXECUTIVE</th>\n",
       "      <td>-27391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Model A-Maisonette</th>\n",
       "      <td>-27842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Maisonette</th>\n",
       "      <td>-37063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Adjoined flat</th>\n",
       "      <td>-42564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Improved</th>\n",
       "      <td>-48408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Model A2</th>\n",
       "      <td>-141194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat_model_Model A</th>\n",
       "      <td>-143807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    lr\n",
       "flat_type_4 ROOM                409476\n",
       "flat_model_Apartment            203541\n",
       "flat_model_Improved-Maisonette  200425\n",
       "mrt_nearest_distance            172242\n",
       "flat_model_DBSS                 159726\n",
       "hdb_age_at_tranc                 93345\n",
       "floor_area_sqm                   87200\n",
       "flat_type_3 ROOM                 81353\n",
       "Mall_Within_500m                 37708\n",
       "flat_type_MULTI-GENERATION       17025\n",
       "Hawker_Nearest_Distance          13770\n",
       "Mall_Nearest_Distance            11448\n",
       "flat_model_Multi Generation       5472\n",
       "flat_type_2 ROOM                 -3524\n",
       "mid                              -4088\n",
       "flat_type_5 ROOM                -24054\n",
       "max_floor_lvl                   -24329\n",
       "flat_type_EXECUTIVE             -27391\n",
       "flat_model_Model A-Maisonette   -27842\n",
       "flat_model_Maisonette           -37063\n",
       "flat_model_Adjoined flat        -42564\n",
       "flat_model_Improved             -48408\n",
       "flat_model_Model A2            -141194\n",
       "flat_model_Model A             -143807"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain coefficients for regular model.\n",
    "\n",
    "get_coefs_df(models_list=[lr_reg])[['lr']].sort_values('lr', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e581b-9c67-4697-bef2-a7604837c7e2",
   "metadata": {},
   "source": [
    "### Regular Model\n",
    "\n",
    "The coefficients in the regular model are somewhat more difficult to interpret, as they don't necessarily fall within expectations. On one hand, it may be a good reflection of how varied people's decision-making processes are. On the other hand, it may also be that some coefficients are not necessarily useful, because those features aren't good predictors of housing prices. That said, it's worth looking into some general trends.\n",
    "\n",
    "Even if we assume that some coefficients may not quite tell the story well, it's safe to assume from the ongoing patterns that flat models are pretty important - they appear at both extreme ends, meaning that at least some of them have a legitimately large impact on housing prices. Categorical features tend to be a little more difficult to account for, because they aren't really 'standalone' features - they do incorporate a lot of other details as well. For example, the coefficients suggest that maisonettes bring down housing prices, but it's not _because_ they are maisonettes - it's probably due to a bunch of other considerations such as age (most of them were built a very long time ago), or even simply that they aren't being readily transacted. In fact, these houses go for quite a lot of money! In the model, however, there could be certain hidden patterns. For example, if there exists a few estates that are pretty similar to the maisonettes in terms of the other features used to build this model, and they are transacting for _higher_ prices, the model may learn from that and leave us with a coefficient that doesn't make intuitive sense.\n",
    "\n",
    "That said, we can get a rough idea of what matters to the average buyer in Singapore. At the very least, features expected to be important do appear - buyers _are_ willing to fork out more money for better connectivity, and potentially prioritise size over age - for now (no flats are even close to the 99-year lease expiry yet). Flat types and models _do_ matter, but there may be a case for treading cautiously here. Common sense would suggest that it's _not_ the case that 4-room flats are exceptionally valuable. They are the single most common flat type, at least in this particular dataset, and that could be why - what happens when a flat is _not_ a 4-room flat in this dataset? It could be that the mean price drops, which would explain why _being_ a 4-room flat becomes very important, at least for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555387e-e12e-44e9-b0e7-94933a157f4d",
   "metadata": {},
   "source": [
    "---\n",
    "## Recommendations & Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38726fc-ad70-4c3c-8551-8db481fd98dc",
   "metadata": {},
   "source": [
    "### Watch out for existing trends\n",
    "\n",
    "Unfortunately, housing prices don't follow a particular year-on-year pattern. Regardless of what the model says, it's always going to be important to keep abreast of current economic trends, world news, government policies, etc. They _do_ have an impact on housing prices, and often not a small one, either.\n",
    "\n",
    "### Be careful when interpreting the model\n",
    "\n",
    "Despite having already been explained above, this point bears additional emphasis. Going at it from a purely mathematical point of view is unlikely to bode well, especially when looking at categorical variables. When attempting to interpret the coefficients, it's important to tie it back to reality to examine how this may _explain_ certain phenomenons, rather than assuming it to be the truth to abide by.\n",
    "\n",
    "### These features are still important\n",
    "\n",
    "There was a warning about coefficients above, but there's always a bright side, of course. The model scores and RMSE values are in fact rather reasonable. It does, at the very least, indicate that the feature selection process was largely a success, and that these features are the ones to look out for, although their relative importance will ultimately depend on the buyer and/or seller.\n",
    "\n",
    "### Consider the buyer's profile\n",
    "\n",
    "If you're looking to _sell_, it would be good to know your target audience. This may be something you come up with on your own, or it could be something that you come up with, based on suitability. After gaining some insights into housing prices in Singapore, it may be worthwhile to examine your house and think of who it's likely to attract. House buying and/or selling can be a stressful and time-consuming process - being able to correctly identify the best target audience for your needs is likely to reduce the amount of time spent on the process, and this in turn reduces the chances of you \"settling\", ie. running out of time (or patience) and accepting a deal that you shouldn't.\n",
    "\n",
    "### Compromise!\n",
    "\n",
    "You can't have the best of both worlds, much less _all_ worlds. Of the recurring trends within the EDA, there's one that should be obvious - houses are never priced _lower_ than what you'd expect. Unfortunately, there's no Shopee for resale flats. Rather than search endlessly for something that doesn't exist, it's better to think about what matters to you, then circle back to this model and see if you have to readjust those priorities. Doing it properly can be the difference between getting a flat you like and are comfortable with, and going with something you can't actually afford. For example, there's little reason to insist on staying within 500m to the MRT station if a flat merely a 100m away goes for $50K cheaper. How do you even know in the first place, without looking through every single listing, that something like this may exist? The answer lies in these notebooks that you've just read - internalise the findings, and apply them accordingly.\n",
    "\n",
    "### What's on the inside matters, too\n",
    "\n",
    "Some things were not covered in this process, because they weren't present as part of the dataset. But they are important, and increasingly so. A good example is interior design. There's a practical aspect to it, too - buyers look at houses and wonder how much extra money they would have to fork out for renovations. You don't even necessarily have to _redo_ your existing house, which wouldn't make sense, but you can certainly spruce it up and make it as presentable as possible. Do your research - instead of simply being amazed by all the oddly high-value resale flats being transacted, try to draw a link between them - what do they have in common? You can always start by using the features from the model as a checklist and branching out from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089319e9-e64c-4357-a540-8a3a38f925b9",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "House-hunting can be a tedious process, and downright a nightmare at times. The purpose of the features selection and modelling process was to discover key features and patterns that prospective buyers and sellers would be able to make use of to reduce their burden. Understanding _why_ certain features impact housing prices is key to unlocking the secrets behind the average buyer's or seller's decision-making process, which would better equip them to 'one-up' the house hunting (buying _and_ selling) process by avoiding the hunting altogether - and simply rely on data and knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64941b-215e-42bd-98b4-ae8cbf80c873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi-sg]",
   "language": "python",
   "name": "conda-env-dsi-sg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
