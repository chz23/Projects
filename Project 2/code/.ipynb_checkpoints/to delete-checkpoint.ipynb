{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbd08d1-6323-4799-ab4f-5caace90dfc4",
   "metadata": {},
   "source": [
    "**NOTES TO SELF**\n",
    "- Everything should be in folders, except for the README.\n",
    "- Continue comments, markdown & docstring!\n",
    "- Keep to 79 letters per line of code as per PEP 8 - use a backslash to split the code.\n",
    "- MUST have title, xlabels & ylabels for ALL charts!\n",
    "- Figure out how to embed link - it doesn't work in git.\n",
    "- Therefore, check every single thing in git before final submission.\n",
    "- Google violin plot, consider using it.\n",
    "- Restart kernel & run all cells before submission!\n",
    "- Make sure slides have more icons & infographics. Not as many words.\n",
    "- Keep to the timing.\n",
    "- Continue with pacing, volume, 'catchy lines' (lol) & interaction w/audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "22394f89-0208-426e-a388-6ae76e292298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from itertools import combinations\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV, ridge_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, mean_absolute_percentage_error, r2_score, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106edb71-f67f-4561-9f6f-f7f989a40e9b",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "---\n",
    "**Key areas**:\n",
    "- Duplicate rows\n",
    "- Null (and equivalent) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "08b3d836-ce2f-447c-ad8f-077d2056fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65902\\AppData\\Local\\Temp\\ipykernel_18596\\4164927454.py:1: DtypeWarning: Columns (41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trn = pd.read_csv('../data/train.csv')\n"
     ]
    }
   ],
   "source": [
    "trn = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "69a71418-27d6-4e48-bfa7-0210d6075ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150634, 77)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0ff22701-be67-400d-93a4-61726c642484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150417 entries, 0 to 150416\n",
      "Data columns (total 77 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   id                         150417 non-null  int64  \n",
      " 1   Tranc_YearMonth            150417 non-null  object \n",
      " 2   town                       150417 non-null  object \n",
      " 3   flat_type                  150417 non-null  object \n",
      " 4   block                      150417 non-null  object \n",
      " 5   street_name                150417 non-null  object \n",
      " 6   storey_range               150417 non-null  object \n",
      " 7   floor_area_sqm             150417 non-null  float64\n",
      " 8   flat_model                 150417 non-null  object \n",
      " 9   lease_commence_date        150417 non-null  int64  \n",
      " 10  resale_price               150417 non-null  float64\n",
      " 11  Tranc_Year                 150417 non-null  int64  \n",
      " 12  Tranc_Month                150417 non-null  int64  \n",
      " 13  mid_storey                 150417 non-null  int64  \n",
      " 14  lower                      150417 non-null  int64  \n",
      " 15  upper                      150417 non-null  int64  \n",
      " 16  mid                        150417 non-null  int64  \n",
      " 17  full_flat_type             150417 non-null  object \n",
      " 18  address                    150417 non-null  object \n",
      " 19  floor_area_sqft            150417 non-null  float64\n",
      " 20  hdb_age                    150417 non-null  int64  \n",
      " 21  max_floor_lvl              150417 non-null  int64  \n",
      " 22  year_completed             150417 non-null  int64  \n",
      " 23  residential                150417 non-null  object \n",
      " 24  commercial                 150417 non-null  object \n",
      " 25  market_hawker              150417 non-null  object \n",
      " 26  multistorey_carpark        150417 non-null  object \n",
      " 27  precinct_pavilion          150417 non-null  object \n",
      " 28  total_dwelling_units       150417 non-null  int64  \n",
      " 29  1room_sold                 150417 non-null  int64  \n",
      " 30  2room_sold                 150417 non-null  int64  \n",
      " 31  3room_sold                 150417 non-null  int64  \n",
      " 32  4room_sold                 150417 non-null  int64  \n",
      " 33  5room_sold                 150417 non-null  int64  \n",
      " 34  exec_sold                  150417 non-null  int64  \n",
      " 35  multigen_sold              150417 non-null  int64  \n",
      " 36  studio_apartment_sold      150417 non-null  int64  \n",
      " 37  1room_rental               150417 non-null  int64  \n",
      " 38  2room_rental               150417 non-null  int64  \n",
      " 39  3room_rental               150417 non-null  int64  \n",
      " 40  other_room_rental          150417 non-null  int64  \n",
      " 41  postal                     150417 non-null  object \n",
      " 42  Latitude                   150417 non-null  float64\n",
      " 43  Longitude                  150417 non-null  float64\n",
      " 44  planning_area              150417 non-null  object \n",
      " 45  Mall_Nearest_Distance      149591 non-null  float64\n",
      " 46  Mall_Within_500m           57758 non-null   float64\n",
      " 47  Mall_Within_1km            125015 non-null  float64\n",
      " 48  Mall_Within_2km            148482 non-null  float64\n",
      " 49  Hawker_Nearest_Distance    150417 non-null  float64\n",
      " 50  Hawker_Within_500m         53171 non-null   float64\n",
      " 51  Hawker_Within_1km          89638 non-null   float64\n",
      " 52  Hawker_Within_2km          121265 non-null  float64\n",
      " 53  hawker_food_stalls         150417 non-null  int64  \n",
      " 54  hawker_market_stalls       150417 non-null  int64  \n",
      " 55  mrt_nearest_distance       150417 non-null  float64\n",
      " 56  mrt_name                   150417 non-null  object \n",
      " 57  bus_interchange            150417 non-null  int64  \n",
      " 58  mrt_interchange            150417 non-null  int64  \n",
      " 59  mrt_latitude               150417 non-null  float64\n",
      " 60  mrt_longitude              150417 non-null  float64\n",
      " 61  bus_stop_nearest_distance  150417 non-null  float64\n",
      " 62  bus_stop_name              150417 non-null  object \n",
      " 63  bus_stop_latitude          150417 non-null  float64\n",
      " 64  bus_stop_longitude         150417 non-null  float64\n",
      " 65  pri_sch_nearest_distance   150417 non-null  float64\n",
      " 66  pri_sch_name               150417 non-null  object \n",
      " 67  vacancy                    150417 non-null  int64  \n",
      " 68  pri_sch_affiliation        150417 non-null  int64  \n",
      " 69  pri_sch_latitude           150417 non-null  float64\n",
      " 70  pri_sch_longitude          150417 non-null  float64\n",
      " 71  sec_sch_nearest_dist       150417 non-null  float64\n",
      " 72  sec_sch_name               150417 non-null  object \n",
      " 73  cutoff_point               150417 non-null  int64  \n",
      " 74  affiliation                150417 non-null  int64  \n",
      " 75  sec_sch_latitude           150417 non-null  float64\n",
      " 76  sec_sch_longitude          150417 non-null  float64\n",
      "dtypes: float64(25), int64(32), object(20)\n",
      "memory usage: 88.4+ MB\n"
     ]
    }
   ],
   "source": [
    "trn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "780899e8-99ec-4649-81f2-9722264a5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates based on all columns except for the 'id' column.\n",
    "# Rationale:\n",
    "# All 'id' values are unique, but a closer look at rows that are identical except for the 'id' column reveals that:\n",
    "# 1) All are other values are identical;\n",
    "# 2) 'id' values for identical columns are usually just 1 digit apart.\n",
    "# The above points, coupled with the fact that it is extremely unlikely that identical sales were made for nearby flats in the same month for the exact same resale price, resulted in the following conclusion:\n",
    "# These duplicates were likely a result of human error (data entry issues) and should be dropped.\n",
    "\n",
    "trn.drop_duplicates(trn.columns[1:], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ed42a094-2dc9-4d1c-ad2e-9b8b0b624ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9ace8-fb00-42e5-998f-1e1e5a60ae3d",
   "metadata": {},
   "source": [
    "#### Dealing with 'NIL' values in the 'postal' column\n",
    "\n",
    "Blocks in the same area ('street_name' column) should have similar postal codes, ie. the first 3 digits should be similar. That said, there may still be a few different types of postal code within the same area. To make a decision on which to assign, latitude and longitude are taken into consideration. Doing so will reveal two things:\n",
    "- First 3 digits of postal codes of blocks closest to the target block;\n",
    "- First 3 digits of postal codes of blocks with block numbers closest to the target block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "13204fe1-91cf-4ca4-971c-c5fef5994bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NIL'], dtype=object)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[trn.postal.str.isnumeric() == False].postal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "bafee97d-4ebc-4689-88c9-635e3d1259e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain distance between two points based on latitude & longitude values.\n",
    "# Mathematical formulas obtained from https://www.geeksforgeeks.org/program-distance-two-points-earth/\n",
    "\n",
    "def distance(df_dist=None, street='', town=None, missing_col=''):\n",
    "    \n",
    "    filtered_cols = ['block', 'postal', 'street_name', 'Mall_Nearest_Distance', 'Mall_Within_500m', 'Mall_Within_1km', 'Mall_Within_2km', 'Longitude', 'Latitude']\n",
    "    \n",
    "    if town == None:\n",
    "        df = df_dist[df_dist.street_name.isin([street])][filtered_cols]\n",
    "        \n",
    "    else:\n",
    "        df = df_dist[df_dist.town.isin([town])][filtered_cols]\n",
    "    \n",
    "    df.drop_duplicates(subset=['Mall_Nearest_Distance', 'Longitude', 'Latitude'], inplace=True)\n",
    "    \n",
    "    df['Longitude'] = df.Longitude.map(lambda x: radians(x))\n",
    "    df['Latitude'] = df.Latitude.map(lambda x: radians(x))\n",
    "        \n",
    "    lon1 = list(df[(df[missing_col].isnull()) & (df.street_name.isin([street]))].Longitude.unique())\n",
    "    lat1 = list(df[(df[missing_col].isnull()) & (df.street_name.isin([street]))].Latitude.unique())\n",
    "    \n",
    "    for i in range(len(lon1)):\n",
    "        \n",
    "        df[f'lon1_{i}'] = lon1[i]\n",
    "        df[f'lat1_{i}'] = lat1[i]\n",
    "        \n",
    "        df[f'dlon_{i}'] = df.Longitude - df[f'lon1_{i}']\n",
    "        df[f'dlat_{i}'] = df.Latitude - df[f'lat1_{i}']\n",
    "        \n",
    "        df[f'a_{i}'] = 0\n",
    "        \n",
    "        df[f'a_{i}'] = df[f'dlat_{i}'].map(lambda x: sin(x / 2)**2) + df[f'lat1_{i}'].map(lambda x: cos(x)) * df.Latitude.map(lambda x: cos(x)) * df[f'dlon_{i}'].map(lambda x: sin(x / 2)**2)\n",
    "        \n",
    "        df[f'c_{i}'] = df[f'a_{i}'].map(lambda x: 2 * asin(sqrt(x)))\n",
    "        \n",
    "        df[f'Distance_{i}'] = df[f'c_{i}'].map(lambda x: x * 6371 * 1000)\n",
    "    \n",
    "    return df.iloc[:, df.columns.map(lambda x: x.startswith(('block', 'postal', 'Mall_Nearest_Distance', 'Distance')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "51e523ce-1329-47cc-9fbf-3d4dabb4775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise values in 'postal' column as str.\n",
    "\n",
    "trn['postal'] = trn.postal.map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "498498c8-bef4-49fb-91c1-8984020102bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'NIL' values in 'postal' column to np.nan.\n",
    "\n",
    "trn['postal'] = trn.postal.map(lambda x: np.nan if x in ['NIL'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "aaee820d-73bd-47ae-9cf8-11642d564c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>215</td>\n",
       "      <td>CHOA CHU KANG CTRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>238</td>\n",
       "      <td>COMPASSVALE WALK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     block         street_name\n",
       "880    215  CHOA CHU KANG CTRL\n",
       "3030   238    COMPASSVALE WALK"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check block & street name of rows that have no postal codes.\n",
    "\n",
    "trn[trn.postal.isnull() == True][['block', 'street_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "507a9fbf-93a1-42ab-81ce-26d4a58b0d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>postal</th>\n",
       "      <th>Mall_Nearest_Distance</th>\n",
       "      <th>Distance_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.156625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>216</td>\n",
       "      <td>680216</td>\n",
       "      <td>299.385682</td>\n",
       "      <td>17.500518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24440</th>\n",
       "      <td>214</td>\n",
       "      <td>680214</td>\n",
       "      <td>303.831770</td>\n",
       "      <td>53.673124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>217</td>\n",
       "      <td>680217</td>\n",
       "      <td>242.948553</td>\n",
       "      <td>60.536651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17218</th>\n",
       "      <td>212</td>\n",
       "      <td>680212</td>\n",
       "      <td>371.138174</td>\n",
       "      <td>74.551625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      block  postal  Mall_Nearest_Distance  Distance_0\n",
       "880     215     NaN             300.156625    0.000000\n",
       "8121    216  680216             299.385682   17.500518\n",
       "24440   214  680214             303.831770   53.673124\n",
       "3751    217  680217             242.948553   60.536651\n",
       "17218   212  680212             371.138174   74.551625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>postal</th>\n",
       "      <th>Mall_Nearest_Distance</th>\n",
       "      <th>Distance_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448.929181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17274</th>\n",
       "      <td>237</td>\n",
       "      <td>540237</td>\n",
       "      <td>464.571810</td>\n",
       "      <td>65.597126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>236</td>\n",
       "      <td>540236</td>\n",
       "      <td>527.031302</td>\n",
       "      <td>86.255979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7567</th>\n",
       "      <td>240</td>\n",
       "      <td>540240</td>\n",
       "      <td>362.051069</td>\n",
       "      <td>86.880028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43090</th>\n",
       "      <td>235</td>\n",
       "      <td>540235</td>\n",
       "      <td>523.986192</td>\n",
       "      <td>109.653587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      block  postal  Mall_Nearest_Distance  Distance_0\n",
       "3030    238     NaN             448.929181    0.000000\n",
       "17274   237  540237             464.571810   65.597126\n",
       "2414    236  540236             527.031302   86.255979\n",
       "7567    240  540240             362.051069   86.880028\n",
       "43090   235  540235             523.986192  109.653587"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the distance() function, check postal codes of blocks nearest to the target block (that has no postal code).\n",
    "\n",
    "display(distance(df_dist=trn, street='CHOA CHU KANG CTRL', missing_col='postal').sort_values('Distance_0').head())\n",
    "\n",
    "display(distance(df_dist=trn, street='COMPASSVALE WALK', missing_col='postal').sort_values('Distance_0').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7ceb17ea-3d56-42bc-9810-f19006f8626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update postal codes of blocks with no postal codes.\n",
    "# First 3 digits: same as that of nearest blocks.\n",
    "# Last 3 digits: block number (all target block numbers are 3 digits long).\n",
    "\n",
    "trn.iloc[trn[(trn.postal.isnull() == True) & (trn.block == '215')].index, 41] = '680215'\n",
    "\n",
    "trn.iloc[trn[(trn.postal.isnull() == True) & (trn.block == '238')].index, 41] = '540238'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930b7fc-84be-47dd-a3ff-8b4b10b25b23",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "**'Mall_Nearest_Distance' column**\n",
    "\n",
    "Like the issue with the postal codes above, this can be roughly approximated using information from blocks closest to the target block. This time, the 'postal', 'Longitude' and 'Latitude' columns will be taken into account. \n",
    "\n",
    "Note that it is extremely unlikely that these blocks are right next to a mall:\n",
    "- There are '0' values for this column, meaning that, for blocks that are right next to a mall, it is reflected in by setting this column's value to '0';\n",
    "- The 3 related columns - 'Mall_Within_500m', 'Mall_Within_1km', 'Mall_Within_2km' - are always empty as well, indicating that there's just generally missing information, or that beyond a certain distance, values are not recorded.\n",
    "\n",
    "**All of the remaining 6 columns**\n",
    "\n",
    "It is likely that the missing values simply mean that there are no malls or hawker centres within the specified area. This is further strengthened by the fact that there are no '0' values across all 6 columns. A check will be done to ensure that this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f26ad89e-ad22-4fe8-9095-bc22762c1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of columns with null values based on the following key: value format:\n",
    "# column name: number of null values\n",
    "\n",
    "nulls = trn.isnull().sum()\n",
    "\n",
    "cols_with_nulls = {nulls.index[i]: nulls[i] for i in range(len(nulls.index)) if nulls[i] != 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5300b29b-4ac9-4d48-a942-812739c52bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mall_Nearest_Distance': 826,\n",
       " 'Mall_Within_500m': 92659,\n",
       " 'Mall_Within_1km': 25402,\n",
       " 'Mall_Within_2km': 1935,\n",
       " 'Hawker_Within_500m': 97246,\n",
       " 'Hawker_Within_1km': 60779,\n",
       " 'Hawker_Within_2km': 29152}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ea198f3e-e34a-420b-86c5-03ac43865fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mall_Nearest_Distance 30\n",
      "Mall_Within_500m 0\n",
      "Mall_Within_1km 0\n",
      "Mall_Within_2km 0\n",
      "Hawker_Within_500m 0\n",
      "Hawker_Within_1km 0\n",
      "Hawker_Within_2km 0\n"
     ]
    }
   ],
   "source": [
    "# For each of the columns in cols_with_nulls, calculate (across all rows in the DataFrame) number of rows with a value of zero.\n",
    "\n",
    "for col in cols_with_nulls.keys():\n",
    "    print(col, trn[trn[col] == 0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "043f5bd7-9fe3-4784-a191-69449c067c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mall_Within_500m    826\n",
       "Mall_Within_1km     826\n",
       "Mall_Within_2km     826\n",
       "dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all rows with a null value in the 'Mall_Nearest_Distance' column aldo have null values in each of the 3 columns starting with 'Mall_Within_...'.\n",
    "\n",
    "trn[trn.Mall_Nearest_Distance.isnull()][['Mall_Within_500m', 'Mall_Within_1km', 'Mall_Within_2km']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "334f6eed-4b84-486c-a186-0829dea8010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of street names that have null values in the 'Mall_Nearest_Distance' column.\n",
    "\n",
    "streets = list(trn[trn.Mall_Nearest_Distance.isnull()].street_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2babe595-efdd-43cf-9ec2-3617a4316e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_and_blocks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "fb4a3773-46cb-4e68-b035-39fb7349780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to \n",
    "# For the specified street:\n",
    "# 1. Create a list of its blocks that have null values in the 'Mall_Nearest_Distance' column.\n",
    "# 2. Add a new key: value pair into the streets_and_blocks dictionary where key = street and value = list of blocks.\n",
    "# 3. Create a list of values extracted from the 'Mall_Nearest_Distance' column using the street & list of blocks as a filter, where...\n",
    "# ...the aim is to ascertain whether there are any houses for the given street and block that do have a valid value in the 'Mall_Nearest_Distance' column.\n",
    "\n",
    "def compare_blocks(df=None, street='', dictionary=None):\n",
    "    \n",
    "    blocks = list(df[df.street_name.isin([street]) & df.Mall_Nearest_Distance.isnull()].block.unique())\n",
    "    \n",
    "    dictionary[street] = blocks\n",
    "    \n",
    "    nearest_mall_dist = list(df[df.street_name.isin([street]) & df.block.isin(blocks)].Mall_Nearest_Distance.unique())\n",
    "    \n",
    "    return nearest_mall_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8686b227-4143-4c4a-8065-c67d091dd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the compare_blocks() function, check that all blocks (for their corresponding streets) with np.nan values in the 'Mall_Nearest_Distance' column...\n",
    "# ...have no valid values in the 'Mall_Nearest_Distance' column.\n",
    "# Ie. All houses for a given target block have np.nan in the 'Mall_Nearest_Distance' column.\n",
    "# This is done to:\n",
    "# 1) Prevent overwriting existing values, and\n",
    "# 2) Check if there are valid values that can be used.\n",
    "\n",
    "for street in streets:\n",
    "    \n",
    "    dist = compare_blocks(df=trn, street=street, dictionary=streets_and_blocks)\n",
    "    \n",
    "    if np.isnan(dist[0]) and len(dist) == 1:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "84c942f6-e231-4fdd-81f2-fd5c6b7c2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store key: value pairs where keys are identical to keys from the streets_and_blocks dictionary.\n",
    "# Create an empty dictionary to store streets that have no valid values in the 'Mall_Nearest_Distance' column, ie. all values are np.nan.\n",
    "\n",
    "# For each street in the 'streets' list:\n",
    "# 1. Apply the distance() function and sort resulting DataFrame by distance.\n",
    "# 2. For each target block, obtain the 'Mall_Nearest_Distance' column value from its closest neighbouring block.\n",
    "# 3. If step 2 doesn't turn up a result, ie. all blocks in the target street have no valid values in the 'Mall_Nearest_Distance' column, add the street to the to_expand_area dictionary.\n",
    "\n",
    "mall_nearest_distance = {street: {} for street in streets_and_blocks.keys()}\n",
    "\n",
    "to_expand_area = {}\n",
    "\n",
    "for street in streets:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        df = distance(df_dist=trn, street=street, missing_col='Mall_Nearest_Distance')\n",
    "\n",
    "        for i in range(3, len(df.columns)):\n",
    "\n",
    "            df_sorted = df.sort_values(df.columns[i])\n",
    "\n",
    "            row = 1\n",
    "            while np.isnan(df_sorted.iloc[row, 2]) == True:\n",
    "                row +=1\n",
    "\n",
    "            mall_nearest_distance[street][df_sorted.iloc[0, 0]] = (df_sorted.iloc[row, 2])\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        to_expand_area[street] = None\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "499478bb-0bc1-43d9-9560-975cc87eaa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each street (key) in the to_expand_area dictionary, obtain its corresponding town (value).\n",
    "\n",
    "for street in to_expand_area:\n",
    "    to_expand_area[street] = trn[trn.street_name.isin([street])].town.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1715848-02e4-4f09-af28-30a500fcbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each street in the to_expand_area dictionary:\n",
    "# 1. Apply the distance() function, this time to the entire town of the target street. Sort resulting DataFrame by distance.\n",
    "# 2. For each target block, obtain the 'Mall_Nearest_Distance' column value from its closest neighbouring block.\n",
    "\n",
    "for street in to_expand_area.keys():\n",
    "    \n",
    "    df = distance(df_dist=trn, street=street, town=to_expand_area[street], missing_col='Mall_Nearest_Distance')\n",
    "\n",
    "    for i in range(3, len(df.columns)):\n",
    "\n",
    "        df_sorted = df.sort_values(df.columns[i])\n",
    "\n",
    "        row = 1\n",
    "        while np.isnan(df_sorted.iloc[row, 2]) == True:\n",
    "            row +=1\n",
    "\n",
    "        mall_nearest_distance[street][df_sorted.iloc[0, 0]] = (df_sorted.iloc[row, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c6029a9-9d57-45e7-95c2-9900801e3ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the column number corresponding to the 'Mall_Nearest_Distance' column.\n",
    "\n",
    "col_num_nearest_mall = [i for i in range(len(trn.columns)) if trn.columns[i] == 'Mall_Nearest_Distance'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce4c5637-f755-4573-a466-886150ef3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only retain rows that have null values for the 'Mall_Nearest_Distance' column.\n",
    "# Replace the null value using the distance value from the mall_nearest_distance dictionary.\n",
    "\n",
    "for street in mall_nearest_distance.keys():\n",
    "    \n",
    "    for block in mall_nearest_distance[street]:\n",
    "        \n",
    "        trn.iloc[trn[(trn.street_name == street) & (trn.block == block)].index, col_num_nearest_mall] = mall_nearest_distance[street][block]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "359d21dd-e29b-4bb6-bc79-086a3d00283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the 3 'Mall_Within_...' columns:\n",
    "# 1. Extract index of rows with null values for target column and filter the DataFrame accordingly.\n",
    "# 2. Replace the null value with either 0 or 1 depending on that row's value for the 'Mall_Nearest_Distance' column .\n",
    "\n",
    "for col, dist in zip(['Mall_Within_500m', 'Mall_Within_1km', 'Mall_Within_2km'], [500, 1000, 2000]):\n",
    "    \n",
    "    col_num = [i for i in range(len(trn.columns)) if trn.columns[i] == col][0]\n",
    "    \n",
    "    trn.iloc[trn[np.isnan(trn[col])].index, col_num] = np.where(trn.iloc[trn[np.isnan(trn[col])].index, col_num_nearest_mall] <= dist, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9695441a-4ae7-4403-b057-f3c15794238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the 3 'Hawker_Within_...' columns:\n",
    "# 1. Check smallest value of Hawker_Nearest_Distance for which the target column has a null value.\n",
    "# 2. If all values > 500, null values will be substituted with 0.\n",
    "\n",
    "for col in ['Hawker_Within_500m', 'Hawker_Within_1km', 'Hawker_Within_2km']:\n",
    "    \n",
    "    if (trn.iloc[trn[trn[col].isnull() == True].index, :].sort_values('Hawker_Nearest_Distance').iloc[1,0] > 500) == True:\n",
    "        \n",
    "        col_num = [i for i in range(len(trn.columns)) if trn.columns[i] == col][0]\n",
    "        \n",
    "        trn.iloc[trn[trn[col].isnull() == True].index, col_num] = 0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a00aed6a-d4f8-4152-a846-5ef82f31995c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there are no more null values.\n",
    "\n",
    "trn.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "944378c2-47a3-492c-8001-61c3655f71cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the 'mid_storey' and 'mid' columns have identical values.\n",
    "\n",
    "(trn.iloc[:, 13] == trn.iloc[:, 16]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f8152d7-5d29-4692-9071-a402c93bff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column that reflects the ate of the HDB flat as at the time it was bought.\n",
    "\n",
    "trn['hdb_age_at_tranc'] = trn['Tranc_Year'] - trn['lease_commence_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d69ab3cf-532e-49a0-84c5-62c4b28c6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a different DataFrame with the relevant columns from trn.\n",
    "\n",
    "df = trn[['flat_type', 'floor_area_sqm', 'flat_model', 'Tranc_Year', 'mid', 'max_floor_lvl', 'planning_area', 'Mall_Nearest_Distance', 'Mall_Within_500m',\n",
    "          'Hawker_Nearest_Distance', 'Hawker_Within_500m', 'mrt_nearest_distance', 'bus_interchange', 'mrt_interchange', 'pri_sch_affiliation', 'sec_sch_nearest_dist',\n",
    "          'cutoff_point', 'affiliation', 'hdb_age_at_tranc', 'resale_price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec18b57-7e8e-4c6e-9b17-29c42d9332c5",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e4dd8e2-60c3-41ee-81ca-fa596ab3c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the date range of data.\n",
    "\n",
    "earliest_year = sorted(trn.Tranc_Year.unique())[0]\n",
    "earliest_month = sorted(trn[trn.Tranc_Year == earliest_year].Tranc_Month.unique())[0]\n",
    "\n",
    "latest_year = sorted(trn.Tranc_Year.unique())[-1]\n",
    "latest_month = sorted(trn[trn.Tranc_Year == latest_year].Tranc_Month.unique())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcfea909-aff5-4806-9e5c-a5b26ab9e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the most characteristic features of flats belonging to the top and bottom 2.5% of flats by the specified filter.\n",
    "# Results will be analysed and used to create three models - one each for 'low-end' flats, 'high-end' flats and 'mid-range' flats.\n",
    "\n",
    "def calc_proportion(df=None, col=None, outlier=None, quantile=None):\n",
    "    \n",
    "    if outlier == 'low':\n",
    "        df_outliers = df[df.resale_price <= df.resale_price.quantile(q=quantile)]\n",
    "        \n",
    "    elif outlier == 'high':\n",
    "        df_outliers = df[df.resale_price >= df.resale_price.quantile(q=quantile)]\n",
    "    \n",
    "    info_by_feature = {}\n",
    "    outliers_info = {}\n",
    "    \n",
    "    df_grouped = df.groupby(col).resale_price.describe().sort_values('mean')\n",
    "    \n",
    "    for feature, count, mean in zip(df_grouped.index, df_grouped['count'], df_grouped['mean']):\n",
    "        info_by_feature[feature] = [count, mean]\n",
    "        \n",
    "    df_outliers = df_outliers.groupby(col).resale_price.describe().sort_values('mean')\n",
    "    \n",
    "    for feature, count, mean in zip(df_outliers.index, df_outliers['count'], df_outliers['mean']):\n",
    "        outliers_info[feature] = [count, mean]\n",
    "        \n",
    "    proportion = {}\n",
    "        \n",
    "    for feature in outliers_info.keys():\n",
    "        proportion[feature] = np.round(outliers_info[feature][0]/info_by_feature[feature][0]*100, 2)\n",
    "        \n",
    "    return pd.DataFrame(proportion.values(), index=proportion.keys(), columns=['proportion_in_percentage']).sort_values('proportion_in_percentage', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93d93d67-fac3-413a-8918-575545188a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating columns into numerical & categorical.\n",
    "\n",
    "numerical_cols = ['floor_area_sqm', 'mid', 'max_floor_lvl', 'Mall_Nearest_Distance', 'Mall_Within_500m', 'Hawker_Nearest_Distance', 'Hawker_Within_500m', \n",
    "                  'mrt_nearest_distance',  'sec_sch_nearest_dist', 'cutoff_point', 'hdb_age_at_tranc']\n",
    "\n",
    "categorical_cols = ['flat_type', 'flat_model', 'Tranc_Year', 'planning_area', 'bus_interchange', 'mrt_interchange', 'pri_sch_affiliation', 'affiliation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e9d8de-8197-45c9-b1ea-f6d52a732c7a",
   "metadata": {},
   "source": [
    "# Modelling - Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bab8c6a1-b6aa-4f89-a705-2619dc005d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features into fixed (will be included in every model) and optional (inclusion depends on model performance).\n",
    "\n",
    "fixed_cols = ['flat_type', 'floor_area_sqm', 'flat_model', 'mid', 'max_floor_lvl', 'planning_area', 'mrt_nearest_distance', 'hdb_age_at_tranc', 'resale_price']\n",
    "optional_cols = [col for col in df.columns if col not in fixed_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f474a11-7b0e-4115-84a5-ad63510cd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_score(df_temp=None, test_size=0.25, random_state=42):\n",
    "    \n",
    "    X_temp = df_temp.drop('resale_price', axis=1)\n",
    "    y_temp = df_temp['resale_price']\n",
    "    \n",
    "    categorical_columns = [col for col in categorical_cols if col in df_temp]\n",
    "    numerical_columns = [col for col in numerical_cols if col in df_temp]\n",
    "    \n",
    "    preprocessor = ColumnTransformer([('one_hot_encoder', OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns), ('standard_scaler', StandardScaler(), numerical_columns)])\n",
    "    lr = make_pipeline(preprocessor, LinearRegression())\n",
    "    \n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X_temp, y_temp, test_size=test_size, random_state=random_state, stratify=None)\n",
    "    lr.fit(X_trn, y_trn)\n",
    "    \n",
    "    return [lr.score(X_trn, y_trn), lr.score(X_tst, y_tst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a3ce47c-bff6-4af4-84dc-2aad7cc6a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_lr(num=None, lst=None, outlier=None, col=None):\n",
    "    col_combis = [list(i) for i in list(combinations(df.drop(fixed_cols, axis=1).columns, num))]\n",
    "\n",
    "    for cols in col_combis:\n",
    "        df_temp = df[fixed_cols+cols]\n",
    "        \n",
    "        if outlier == 'low':\n",
    "            if col == 'flat_type':\n",
    "                df_temp = df_temp[(df_temp.flat_type == '1 ROOM') | (df_temp.flat_type == '2 ROOM')]\n",
    "            elif col == 'floor_area_sqm':\n",
    "                df_temp = df_temp[df_temp.floor_area_sqm <= 48]\n",
    "            elif col == 'hdb_age_at_tranc':\n",
    "                df_temp = df_temp[df_temp.hdb_age_at_tranc >= 48]\n",
    "            \n",
    "        elif outlier == 'high':\n",
    "            if col == 'floor_area_sqm':\n",
    "                df_temp = df_temp[df_temp.floor_area_sqm >= 180]\n",
    "            elif col == 'flat_model':\n",
    "                df_temp = df_temp[(df_temp.flat_model == 'Type S2') | (df_temp.flat_model == 'Type S1') | (df_temp.flat_model == 'Premium Apartment Loft') | (df_temp.flat_model == 'Terrace') | (df_temp.flat_model == 'DBSS')]\n",
    "            elif col == 'mid':\n",
    "                df_temp = df_temp[df_temp.mid >= 29]\n",
    "            elif col == 'max_floor_lvl':\n",
    "                df_temp = df_temp[(df_temp.max_floor_lvl >= 40) | ((df_temp.max_floor_lvl <= 2) & (df_temp.flat_model == 'Terrace'))]\n",
    "            elif col == 'planning_area':\n",
    "                df_temp = df_temp[(df_temp.planning_area == 'Tanglin') | (df_temp.planning_area == 'Outram') | (df_temp.planning_area == 'Bukit Timah')]\n",
    "                \n",
    "        elif outlier == None:\n",
    "            df_temp = df_temp[(df_temp.hdb_age_at_tranc < 48) & (df_temp.planning_area != 'Tanglin') & (df_temp.planning_area != 'Outram') & (df_temp.planning_area != 'Bukit Timah')]\n",
    "\n",
    "        scores = get_lr_score(df_temp=df_temp)\n",
    "\n",
    "        if scores[0] < 0.7 or scores[1] < 0.7:\n",
    "            continue\n",
    "        else:\n",
    "            lst.append([outlier, col, df_temp.shape[0]])\n",
    "            lst[-1] += scores\n",
    "            lst[-1] += cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd1dfcd8-a18b-4f71-8f09-020025cce643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_l1_l2_cv(model_type=None, df_model=None, test_size=0.2, random_state=42):\n",
    "    \n",
    "    X = df_model.drop('resale_price', axis=1)\n",
    "    y = df_model['resale_price']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=None)\n",
    "    \n",
    "    categorical_columns = [col for col in categorical_cols if col in df_model]\n",
    "    numerical_columns = [col for col in numerical_cols if col in df_model]\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train[numerical_columns])\n",
    "    X_train_ss = ss.transform(X_train[numerical_columns])\n",
    "    X_test_ss = ss.transform(X_test[numerical_columns])\n",
    "    \n",
    "    ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "    ohe.fit(X_train[categorical_columns])\n",
    "    X_train_ohe = ohe.transform(X_train[categorical_columns])\n",
    "    X_test_ohe = ohe.transform(X_test[categorical_columns])\n",
    "    \n",
    "    X_train_processed = np.concatenate([X_train_ss, X_train_ohe], axis=1)\n",
    "    X_test_processed = np.concatenate([X_test_ss, X_test_ohe], axis=1)\n",
    "    \n",
    "    if model_type == 'lr':\n",
    "        model = LinearRegression()\n",
    " \n",
    "    elif model_type == 'l1':       \n",
    "        model = LassoCV(n_alphas=100, cv=5)\n",
    "\n",
    "    elif model_type == 'l2':     \n",
    "        model = RidgeCV(alphas=np.logspace(0, 5, 100), cv=5)\n",
    "        \n",
    "    model.fit(X_train_processed, y_train)\n",
    "        \n",
    "    return [model, \n",
    "            model.score(X_train_processed, y_train), model.score(X_test_processed, y_test), \n",
    "            list(ss.get_feature_names_out(numerical_columns))+list(ohe.get_feature_names_out(categorical_columns))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b97968-6706-45e2-955f-cf93fc28b087",
   "metadata": {},
   "source": [
    "# Modelling - separating `df` into low/mid/high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af606643-1df6-4c93-bbfe-4c8c5b8de8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr_outliers = pd.read_csv('../data/df_lr_outliers.csv')\n",
    "df_lr_outliers.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "117926b6-4f23-471b-ad99-9bbb5cea493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>filter_col</th>\n",
       "      <th>size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>additional_col_1</th>\n",
       "      <th>additional_col_2</th>\n",
       "      <th>additional_col_3</th>\n",
       "      <th>additional_col_4</th>\n",
       "      <th>additional_col_5</th>\n",
       "      <th>additional_col_6</th>\n",
       "      <th>additional_col_7</th>\n",
       "      <th>additional_col_8</th>\n",
       "      <th>additional_col_9</th>\n",
       "      <th>additional_col_10</th>\n",
       "      <th>additional_col_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11571</th>\n",
       "      <td>high</td>\n",
       "      <td>planning_area</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.967201</td>\n",
       "      <td>0.964865</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>cutoff_point</td>\n",
       "      <td>affiliation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11439</th>\n",
       "      <td>high</td>\n",
       "      <td>planning_area</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.967168</td>\n",
       "      <td>0.964694</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>cutoff_point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11594</th>\n",
       "      <td>high</td>\n",
       "      <td>planning_area</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.967167</td>\n",
       "      <td>0.964879</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Mall_Within_500m</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>affiliation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11435</th>\n",
       "      <td>high</td>\n",
       "      <td>planning_area</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.964464</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>cutoff_point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>high</td>\n",
       "      <td>planning_area</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.967152</td>\n",
       "      <td>0.964889</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>cutoff_point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type     filter_col  size  train_score  test_score additional_col_1  \\\n",
       "11571  high  planning_area  1146     0.967201    0.964865       Tranc_Year   \n",
       "11439  high  planning_area  1146     0.967168    0.964694       Tranc_Year   \n",
       "11594  high  planning_area  1146     0.967167    0.964879       Tranc_Year   \n",
       "11435  high  planning_area  1146     0.967153    0.964464       Tranc_Year   \n",
       "11566  high  planning_area  1146     0.967152    0.964889       Tranc_Year   \n",
       "\n",
       "            additional_col_2         additional_col_3  \\\n",
       "11571  Mall_Nearest_Distance  Hawker_Nearest_Distance   \n",
       "11439  Mall_Nearest_Distance  Hawker_Nearest_Distance   \n",
       "11594  Mall_Nearest_Distance         Mall_Within_500m   \n",
       "11435  Mall_Nearest_Distance  Hawker_Nearest_Distance   \n",
       "11566  Mall_Nearest_Distance  Hawker_Nearest_Distance   \n",
       "\n",
       "              additional_col_4    additional_col_5     additional_col_6  \\\n",
       "11571       Hawker_Within_500m     mrt_interchange  pri_sch_affiliation   \n",
       "11439       Hawker_Within_500m     mrt_interchange  pri_sch_affiliation   \n",
       "11594  Hawker_Nearest_Distance  Hawker_Within_500m      bus_interchange   \n",
       "11435       Hawker_Within_500m     bus_interchange  pri_sch_affiliation   \n",
       "11566       Hawker_Within_500m     bus_interchange      mrt_interchange   \n",
       "\n",
       "           additional_col_7      additional_col_8      additional_col_9  \\\n",
       "11571  sec_sch_nearest_dist          cutoff_point           affiliation   \n",
       "11439  sec_sch_nearest_dist          cutoff_point                   NaN   \n",
       "11594       mrt_interchange   pri_sch_affiliation  sec_sch_nearest_dist   \n",
       "11435  sec_sch_nearest_dist          cutoff_point                   NaN   \n",
       "11566   pri_sch_affiliation  sec_sch_nearest_dist          cutoff_point   \n",
       "\n",
       "      additional_col_10 additional_col_11  \n",
       "11571               NaN               NaN  \n",
       "11439               NaN               NaN  \n",
       "11594       affiliation               NaN  \n",
       "11435               NaN               NaN  \n",
       "11566               NaN               NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr_outliers[(abs(df_lr_outliers.train_score - df_lr_outliers.test_score) <= 0.005) & (df_lr_outliers.type == 'high')].sort_values('train_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d85f170-1db1-48f8-a2da-04ed4b99605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lr_outliers[df_lr_outliers.type == 'low'][[f'additional_col_{i}' for i in range(1,12)]].apply(pd.Series.value_counts).transpose().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3cb740e-b19f-4089-98c1-bd3fa317d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.read_csv('../data/df_lr.csv')\n",
    "df_lr.drop(['Unnamed: 0', 'type', 'filter_col'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d5a8217-eae9-4b5f-8b49-f534e9796746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>additional_col_1</th>\n",
       "      <th>additional_col_2</th>\n",
       "      <th>additional_col_3</th>\n",
       "      <th>additional_col_4</th>\n",
       "      <th>additional_col_5</th>\n",
       "      <th>additional_col_6</th>\n",
       "      <th>additional_col_7</th>\n",
       "      <th>additional_col_8</th>\n",
       "      <th>additional_col_9</th>\n",
       "      <th>additional_col_10</th>\n",
       "      <th>additional_col_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>147355</td>\n",
       "      <td>0.888265</td>\n",
       "      <td>0.888698</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Mall_Within_500m</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>cutoff_point</td>\n",
       "      <td>affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>147355</td>\n",
       "      <td>0.888257</td>\n",
       "      <td>0.888704</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Mall_Within_500m</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>cutoff_point</td>\n",
       "      <td>affiliation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>147355</td>\n",
       "      <td>0.888245</td>\n",
       "      <td>0.888675</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Mall_Within_500m</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>affiliation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>147355</td>\n",
       "      <td>0.888233</td>\n",
       "      <td>0.888682</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Mall_Within_500m</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>Hawker_Within_500m</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>affiliation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>147355</td>\n",
       "      <td>0.888155</td>\n",
       "      <td>0.888631</td>\n",
       "      <td>Tranc_Year</td>\n",
       "      <td>Mall_Nearest_Distance</td>\n",
       "      <td>Mall_Within_500m</td>\n",
       "      <td>Hawker_Nearest_Distance</td>\n",
       "      <td>bus_interchange</td>\n",
       "      <td>mrt_interchange</td>\n",
       "      <td>pri_sch_affiliation</td>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>cutoff_point</td>\n",
       "      <td>affiliation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        size  train_score  test_score additional_col_1       additional_col_2  \\\n",
       "2047  147355     0.888265    0.888698       Tranc_Year  Mall_Nearest_Distance   \n",
       "2039  147355     0.888257    0.888704       Tranc_Year  Mall_Nearest_Distance   \n",
       "2037  147355     0.888245    0.888675       Tranc_Year  Mall_Nearest_Distance   \n",
       "1985  147355     0.888233    0.888682       Tranc_Year  Mall_Nearest_Distance   \n",
       "2042  147355     0.888155    0.888631       Tranc_Year  Mall_Nearest_Distance   \n",
       "\n",
       "      additional_col_3         additional_col_4    additional_col_5  \\\n",
       "2047  Mall_Within_500m  Hawker_Nearest_Distance  Hawker_Within_500m   \n",
       "2039  Mall_Within_500m  Hawker_Nearest_Distance  Hawker_Within_500m   \n",
       "2037  Mall_Within_500m  Hawker_Nearest_Distance  Hawker_Within_500m   \n",
       "1985  Mall_Within_500m  Hawker_Nearest_Distance  Hawker_Within_500m   \n",
       "2042  Mall_Within_500m  Hawker_Nearest_Distance     bus_interchange   \n",
       "\n",
       "     additional_col_6     additional_col_7      additional_col_8  \\\n",
       "2047  bus_interchange      mrt_interchange   pri_sch_affiliation   \n",
       "2039  bus_interchange      mrt_interchange  sec_sch_nearest_dist   \n",
       "2037  bus_interchange      mrt_interchange   pri_sch_affiliation   \n",
       "1985  bus_interchange      mrt_interchange  sec_sch_nearest_dist   \n",
       "2042  mrt_interchange  pri_sch_affiliation  sec_sch_nearest_dist   \n",
       "\n",
       "          additional_col_9 additional_col_10 additional_col_11  \n",
       "2047  sec_sch_nearest_dist      cutoff_point       affiliation  \n",
       "2039          cutoff_point       affiliation               NaN  \n",
       "2037  sec_sch_nearest_dist       affiliation               NaN  \n",
       "1985           affiliation               NaN               NaN  \n",
       "2042          cutoff_point       affiliation               NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr[abs(df_lr.train_score - df_lr.test_score) <= 0.005].sort_values('train_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efc966df-374b-4fb7-aab8-93f6da95505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lr[[f'additional_col_{i}' for i in range(1,11)]].apply(pd.Series.value_counts).transpose().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e7158af9-a79a-450d-9ff4-9ac9eed75435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low = df[(df.hdb_age_at_tranc >= 48)].drop(['Tranc_Year', 'Hawker_Nearest_Distance', 'pri_sch_affiliation', 'sec_sch_nearest_dist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "846e1f23-e75f-4b2f-a6cf-a7e1752d9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = df[(df.planning_area == 'Tanglin') | (df.planning_area == 'Outram') | (df.planning_area == 'Bukit Timah')].drop(['Mall_Within_500m', 'bus_interchange'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2a6c048f-ccbc-4502-8f76-0f05c5469796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mid = df[(df.hdb_age_at_tranc < 48) & (df.planning_area != 'Tanglin') & (df.planning_area != 'Outram') & (df.planning_area != 'Bukit Timah')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58799a-cd0e-4598-9efb-adb15537a8ff",
   "metadata": {},
   "source": [
    "# Modelling (LR) - low/mid/high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d3074a0-a1f6-48ec-a5ca-98030d77c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_low = lr_l1_l2_cv(model_type='lr', df_model=df_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "656e1f85-f408-4181-809e-251e06379ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_high = lr_l1_l2_cv(model_type='lr', df_model=df_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa22848b-268b-4ad4-8fcb-5d273ccb225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mid = lr_l1_l2_cv(model_type='lr', df_model=df_mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d36735-e33a-49fb-95df-b8bce8a0a6cf",
   "metadata": {},
   "source": [
    "# Modelling (Ridge) - low/mid/high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7a64d4b-6fa5-45f0-b8c4-4aef801d3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_low = lr_l1_l2_cv(model_type='l2', df_model=df_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "793c26b8-a8dd-4f3c-97a4-7fb9c7d0e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_high = lr_l1_l2_cv(model_type='l2', df_model=df_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcbeaa10-93e0-4dbf-b2ff-276b86974f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_mid = lr_l1_l2_cv(model_type='l2', df_model=df_mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a0036f-d7eb-4670-9e6c-f2883454df26",
   "metadata": {},
   "source": [
    "# Modelling (Lasso) - low/mid/high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30375ec3-5895-4559-93de-c1ed3aeec794",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_low = lr_l1_l2_cv(model_type='l1', df_model=df_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c44e7a83-2479-4962-8b89-b2ee0aa3e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_high = lr_l1_l2_cv(model_type='l1', df_model=df_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e090599-a694-44f2-833a-5c73526b3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_mid = lr_l1_l2_cv(model_type='l1', df_model=df_mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff30416-b4f9-430e-94bd-85e68d257419",
   "metadata": {},
   "source": [
    "# Modelling - comparing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2f9099e-f9a9-43e0-92ed-331184ab0d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8880643938942949, 0.8942678961134312],\n",
       " [0.88688893958256, 0.8919990831218172],\n",
       " [0.8871163993575322, 0.8936688867994856])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_low[1:3], ridge_low[1:3], lasso_low[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03551a20-b5f9-4320-bdc2-47adf8d93a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9672303918911014, 0.9646632134173642],\n",
       " [0.9652558865680674, 0.9633061995993794],\n",
       " [0.9647179612398966, 0.9640090398270454])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_high[1:3], ridge_high[1:3], lasso_high[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4aff7c46-1f35-47d1-be70-29a691c0f8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8882649537041322, 0.8886958697264602],\n",
       " [0.8882595759205115, 0.8887007934603197],\n",
       " [0.8843034767694236, 0.8852096627454584])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mid[1:3], ridge_mid[1:3], lasso_mid[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ea3c3-7fa1-4bf6-8b57-94b36703342c",
   "metadata": {},
   "source": [
    "# Modelling - comparing coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73efa9e9-a6fe-4824-b855-fb6f2fffd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_low = [lr_low, ridge_low, lasso_low]\n",
    "models_high = [lr_high, ridge_high, lasso_high]\n",
    "models_mid = [lr_mid, ridge_mid, lasso_mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cee09c1-96a0-4b98-91dd-a1d7b6737b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs_df(models_list=None):\n",
    "    coefs = [int(models_list[i][0].coef_[x]) for x in range(len(models_list[0][0].coef_)) for i in range(len(models_list))]\n",
    "    coefs_dict = {feature: lst for feature, lst in zip(models_list[0][-1], [coefs[i:i+3] for i in range(0, len(coefs), 3)])}\n",
    "\n",
    "    df_coefs = pd.DataFrame.from_dict(coefs_dict,\n",
    "                                      orient='index',\n",
    "                                      columns=['lr', 'ridge', 'lasso'])\n",
    "    \n",
    "    return df_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7327441-dc13-441c-91a0-08c999a6bddf",
   "metadata": {},
   "source": [
    "# Code for data that were converted into .csv files\n",
    "---\n",
    "**Relevant .csv files**:\n",
    "- df_lr_outliers.csv\n",
    "- df_lr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7fe325e6-4e0e-4b8f-974c-5a0096ab9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_combis_outliers = []\n",
    "\n",
    "# for outlier, col in zip(['low' for i in range(3)]+['high' for i in range(5)], \n",
    "#                         ['flat_type', 'floor_area_sqm', 'hdb_age_at_tranc', 'floor_area_sqm', 'flat_model', 'mid', 'max_floor_lvl', 'planning_area']):\n",
    "    \n",
    "#     for i in range(len(optional_cols)+1):\n",
    "        \n",
    "#         conditional_lr(num=i, lst=optimal_combis_outliers, outlier=outlier, col=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51be3ea8-6f50-40bd-908d-5be360108394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_combis_outliers_dict = {i: lst for i, lst in zip(range(len(optimal_combis_outliers)), optimal_combis_outliers)}\n",
    "\n",
    "# df_lr_outliers = pd.DataFrame.from_dict(optimal_combis_outliers_dict,\n",
    "#                                       orient='index',\n",
    "#                                       columns=['type', 'filter_col', 'size', 'train_score', 'test_score']+[f'additional_col_{i}' for i in range(1, len(optional_cols)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b65a46e-01ca-40d8-a6ff-89ff095f051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lr_outliers.to_csv('../data/df_lr_outliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7cefa0d-d743-4ab6-95cc-05924bd7f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_combis = []\n",
    "    \n",
    "# for i in range(len(optional_cols)+1):\n",
    "\n",
    "#     conditional_lr(num=i, lst=optimal_combis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "005c735f-eedf-444c-9268-4448f93c0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_combis_dict = {i: lst for i, lst in zip(range(len(optimal_combis)), optimal_combis)}\n",
    "\n",
    "# df_lr = pd.DataFrame.from_dict(optimal_combis_dict,\n",
    "#                                orient='index',\n",
    "#                                columns=['type', 'filter_col', 'size', 'train_score', 'test_score']+[f'additional_col_{i}' for i in range(1, len(optional_cols)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "829e6148-0974-4ce8-b265-165303c604e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lr.to_csv('../data/df_lr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d70c2d-52bc-4ad3-8035-b572236e1bb7",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c6744120-32e8-433f-8bbd-eeaa5cd137bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65902\\AppData\\Local\\Temp\\ipykernel_18596\\485150523.py:1: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tst = pd.read_csv('../data/test.csv')\n"
     ]
    }
   ],
   "source": [
    "tst = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca8d2ea2-5b18-4477-ad2a-c3be9952d809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NIL'], dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst[tst.postal.str.isnumeric() == False].postal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eab3f626-3daf-44eb-a670-5470d19b7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise values in 'postal' column as str.\n",
    "\n",
    "tst['postal'] = tst.postal.map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "10d737a7-7868-40bb-89dc-f607fe9c61db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'NIL' values in 'postal' column to np.nan.\n",
    "\n",
    "tst['postal'] = tst.postal.map(lambda x: np.nan if x in ['NIL'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1fe2f118-07de-463d-ac3f-4bdb3516f0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>238</td>\n",
       "      <td>COMPASSVALE WALK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     block       street_name\n",
       "5137   238  COMPASSVALE WALK"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check block & street name of rows that have no postal codes.\n",
    "\n",
    "tst[tst.postal.isnull() == True][['block', 'street_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "96c24882-f30d-46f3-865b-e337aee63525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>postal</th>\n",
       "      <th>Mall_Nearest_Distance</th>\n",
       "      <th>Distance_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448.929181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>236</td>\n",
       "      <td>540236</td>\n",
       "      <td>527.031302</td>\n",
       "      <td>86.254314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9349</th>\n",
       "      <td>240</td>\n",
       "      <td>540240</td>\n",
       "      <td>362.051069</td>\n",
       "      <td>86.881562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13157</th>\n",
       "      <td>235</td>\n",
       "      <td>540235</td>\n",
       "      <td>523.986192</td>\n",
       "      <td>109.652115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>239</td>\n",
       "      <td>540239</td>\n",
       "      <td>363.858400</td>\n",
       "      <td>113.716682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      block  postal  Mall_Nearest_Distance  Distance_0\n",
       "5137    238     NaN             448.929181    0.000000\n",
       "58      236  540236             527.031302   86.254314\n",
       "9349    240  540240             362.051069   86.881562\n",
       "13157   235  540235             523.986192  109.652115\n",
       "833     239  540239             363.858400  113.716682"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the distance() function, check postal codes of blocks nearest to the target block (that has no postal code).\n",
    "\n",
    "display(distance(df_dist=tst, street='COMPASSVALE WALK', missing_col='postal').sort_values('Distance_0').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0c5ecdbf-bc6c-4f90-ad2a-a24b22786e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update postal codes of blocks with no postal codes.\n",
    "# First 3 digits: same as that of nearest blocks.\n",
    "# Last 3 digits: block number (all target block numbers are 3 digits long).\n",
    "\n",
    "tst.iloc[tst[(tst.postal.isnull() == True) & (tst.block == '238')].index, 40] = '540238'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0e58db5e-2462-4673-acc9-316674a07266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of columns with null values based on the following key: value format:\n",
    "# column name: number of null values\n",
    "\n",
    "nulls_tst = tst.isnull().sum()\n",
    "\n",
    "cols_with_nulls_tst = {nulls_tst.index[i]: nulls_tst[i] for i in range(len(nulls_tst.index)) if nulls_tst[i] != 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ced49866-887c-4bff-87fe-80b30a619012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mall_Nearest_Distance': 84,\n",
       " 'Mall_Within_500m': 10292,\n",
       " 'Mall_Within_1km': 2786,\n",
       " 'Mall_Within_2km': 213,\n",
       " 'Hawker_Within_500m': 10755,\n",
       " 'Hawker_Within_1km': 6729,\n",
       " 'Hawker_Within_2km': 3254}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_nulls_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ac4cf930-5d5d-4afe-a1b3-4425785d494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of street names that have null values in the 'Mall_Nearest_Distance' column.\n",
    "\n",
    "streets_tst = list(tst[tst.Mall_Nearest_Distance.isnull()].street_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c159201e-0f9a-49cf-9593-567a52bc5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_and_blocks_tst = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "328dabe6-29c9-4b17-b1bd-441c5ccb0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the compare_blocks() function, check that all blocks (for their corresponding streets) with np.nan values in the 'Mall_Nearest_Distance' column...\n",
    "# ...have no valid values in the 'Mall_Nearest_Distance' column.\n",
    "# Ie. All houses for a given target block have np.nan in the 'Mall_Nearest_Distance' column.\n",
    "# This is done to:\n",
    "# 1) Prevent overwriting existing values, and\n",
    "# 2) Check if there are valid values that can be used.\n",
    "\n",
    "for street in streets_tst:\n",
    "    \n",
    "    dist = compare_blocks(df=tst, street=street, dictionary=streets_and_blocks_tst)\n",
    "                          \n",
    "    if np.isnan(dist[0]) and len(dist) == 1:\n",
    "        pass\n",
    "                          \n",
    "    else:\n",
    "        print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "96b9ca3d-ff5a-4e1c-affb-0cca021f3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store key: value pairs where keys are identical to keys from the streets_and_blocks dictionary.\n",
    "# Create an empty dictionary to store streets that have no valid values in the 'Mall_Nearest_Distance' column, ie. all values are np.nan.\n",
    "\n",
    "# For each street in the 'streets' list:\n",
    "# 1. Apply the distance() function and sort resulting DataFrame by distance.\n",
    "# 2. For each target block, obtain the 'Mall_Nearest_Distance' column value from its closest neighbouring block.\n",
    "# 3. If step 2 doesn't turn up a result, ie. all blocks in the target street have no valid values in the 'Mall_Nearest_Distance' column, add the street to the to_expand_area dictionary.\n",
    "\n",
    "mall_nearest_distance_tst = {street: {} for street in streets_and_blocks_tst.keys()}\n",
    "\n",
    "to_expand_area_tst = {}\n",
    "\n",
    "for street in streets_tst:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        df_tst = distance(df_dist=tst, street=street, missing_col='Mall_Nearest_Distance')\n",
    "\n",
    "        for i in range(3, len(df_tst.columns)):\n",
    "\n",
    "            df_sorted_tst = df_tst.sort_values(df_tst.columns[i])\n",
    "\n",
    "            row = 1\n",
    "            while np.isnan(df_sorted_tst.iloc[row, 2]) == True:\n",
    "                row +=1\n",
    "\n",
    "            mall_nearest_distance_tst[street][df_sorted_tst.iloc[0, 0]] = (df_sorted_tst.iloc[row, 2])\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        to_expand_area_tst[street] = None\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b9b063ed-5171-43ad-b391-b3cc9a627f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each street (key) in the to_expand_area dictionary, obtain its corresponding town (value).\n",
    "\n",
    "for street in to_expand_area_tst:\n",
    "    to_expand_area_tst[street] = tst[tst.street_name.isin([street])].town.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "294b248e-0f8f-492a-973b-ae4fb08777d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each street in the to_expand_area dictionary:\n",
    "# 1. Apply the distance() function, this time to the entire town of the target street. Sort resulting DataFrame by distance.\n",
    "# 2. For each target block, obtain the 'Mall_Nearest_Distance' column value from its closest neighbouring block.\n",
    "\n",
    "for street in to_expand_area_tst.keys():\n",
    "    \n",
    "    df_tst = distance(df_dist=tst, street=street, town=to_expand_area_tst[street], missing_col='Mall_Nearest_Distance')\n",
    "\n",
    "    for i in range(3, len(df_tst.columns)):\n",
    "\n",
    "        df_sorted_tst = df_tst.sort_values(df_tst.columns[i])\n",
    "\n",
    "        row = 1\n",
    "        while np.isnan(df_sorted_tst.iloc[row, 2]) == True:\n",
    "            row +=1\n",
    "\n",
    "        mall_nearest_distance_tst[street][df_sorted_tst.iloc[0, 0]] = (df_sorted_tst.iloc[row, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c696d718-8c13-4136-8eb2-d773413fc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the column number corresponding to the 'Mall_Nearest_Distance' column.\n",
    "\n",
    "col_num_nearest_mall_tst = [i for i in range(len(tst.columns)) if tst.columns[i] == 'Mall_Nearest_Distance'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a782a377-e610-43b8-8314-5dd0811dc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to only retain rows that have null values for the 'Mall_Nearest_Distance' column.\n",
    "# Replace the null value using the distance value from the mall_nearest_distance dictionary.\n",
    "\n",
    "for street in mall_nearest_distance_tst.keys():\n",
    "    \n",
    "    for block in mall_nearest_distance_tst[street]:\n",
    "        \n",
    "        tst.iloc[tst[(tst.street_name == street) & (tst.block == block)].index, col_num_nearest_mall_tst] = mall_nearest_distance_tst[street][block]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9a84cfdb-ee45-4f0c-861a-96efd4cded85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the 3 'Mall_Within_...' columns:\n",
    "# 1. Extract index of rows with null values for target column and filter the DataFrame accordingly.\n",
    "# 2. Replace the null value with either 0 or 1 depending on that row's value for the 'Mall_Nearest_Distance' column .\n",
    "\n",
    "for col, dist in zip(['Mall_Within_500m', 'Mall_Within_1km', 'Mall_Within_2km'], [500, 1000, 2000]):\n",
    "    \n",
    "    col_num = [i for i in range(len(tst.columns)) if tst.columns[i] == col][0]\n",
    "    \n",
    "    tst.iloc[tst[np.isnan(tst[col])].index, col_num] = np.where(tst.iloc[tst[np.isnan(tst[col])].index, col_num_nearest_mall_tst] <= dist, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2f31bdee-0521-4b91-b2d3-3270b3981017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the 3 'Hawker_Within_...' columns:\n",
    "# 1. Check smallest value of Hawker_Nearest_Distance for which the target column has a null value.\n",
    "# 2. If all values > 500, null values will be substituted with 0.\n",
    "\n",
    "for col in ['Hawker_Within_500m', 'Hawker_Within_1km', 'Hawker_Within_2km']:\n",
    "    \n",
    "    if (tst.iloc[tst[tst[col].isnull() == True].index, :].sort_values('Hawker_Nearest_Distance').iloc[1,0] > 500) == True:\n",
    "        \n",
    "        col_num = [i for i in range(len(tst.columns)) if tst.columns[i] == col][0]\n",
    "        \n",
    "        tst.iloc[tst[tst[col].isnull() == True].index, col_num] = 0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3adc4ff0-3d6e-4fdb-a333-c953e6a685b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there are no more null values.\n",
    "\n",
    "tst.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8fcfb999-84d0-4a15-9083-0484cf7825ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column that reflects the ate of the HDB flat as at the time it was bought.\n",
    "\n",
    "tst['hdb_age_at_tranc'] = tst['Tranc_Year'] - tst['lease_commence_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e2fbb699-3829-421c-9853-efc8a1e83c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a different DataFrame with the relevant columns from trn.\n",
    "\n",
    "df_tst = tst[['id', 'flat_type', 'floor_area_sqm', 'flat_model', 'Tranc_Year', 'mid', 'max_floor_lvl', 'planning_area', 'Mall_Nearest_Distance', 'Mall_Within_500m',\n",
    "          'Hawker_Nearest_Distance', 'Hawker_Within_500m', 'mrt_nearest_distance', 'bus_interchange', 'mrt_interchange', 'pri_sch_affiliation', 'sec_sch_nearest_dist',\n",
    "          'cutoff_point', 'affiliation', 'hdb_age_at_tranc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "41566e17-c2a6-42c1-b4b6-ec76564269eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test_data(df_model=None):\n",
    "    \n",
    "    # df_id = df_model['id']\n",
    "    \n",
    "    df_model = df_model.drop('id', axis=1)\n",
    "    \n",
    "    categorical_columns = [col for col in categorical_cols if col in df_model]\n",
    "    numerical_columns = [col for col in numerical_cols if col in df_model]\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    df_ss = ss.fit_transform(df_model[numerical_columns])\n",
    "    \n",
    "    ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "    df_ohe = ohe.fit_transform(df_model[categorical_columns])\n",
    "    \n",
    "    df_processed = np.concatenate([df_ss, df_ohe], axis=1)\n",
    "    \n",
    "    # return [df_id, df_processed]\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "56748467-1243-461f-ba53-5ef312a5f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low_tst = df_tst[(df_tst.hdb_age_at_tranc >= 48)].drop(['Tranc_Year', 'Hawker_Nearest_Distance', 'pri_sch_affiliation', 'sec_sch_nearest_dist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c2c620ab-db49-4f34-abe5-c3679a76ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65902\\AppData\\Local\\Temp\\ipykernel_18596\\2826666526.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_high_tst = df_tst[(df_tst.planning_area == 'Tanglin') | (df.planning_area == 'Outram') | (df.planning_area == 'Bukit Timah')].drop(['Mall_Within_500m', 'bus_interchange'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_high_tst = df_tst[(df_tst.planning_area == 'Tanglin') | (df.planning_area == 'Outram') | (df.planning_area == 'Bukit Timah')].drop(['Mall_Within_500m', 'bus_interchange'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3c22fb29-44bb-48e5-930e-d03dcc47310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65902\\AppData\\Local\\Temp\\ipykernel_18596\\2199649429.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_mid_tst = df_tst[(df_tst.hdb_age_at_tranc < 48) & (df.planning_area != 'Tanglin') & (df.planning_area != 'Outram') & (df.planning_area != 'Bukit Timah')]\n"
     ]
    }
   ],
   "source": [
    "df_mid_tst = df_tst[(df_tst.hdb_age_at_tranc < 48) & (df.planning_area != 'Tanglin') & (df.planning_area != 'Outram') & (df.planning_area != 'Bukit Timah')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "124a9d33-a44b-46aa-ab0d-7f364e840654",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 64 features, but LinearRegression is expecting 36 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [263], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# df_low_tst_id, df_low_tst_processed = prep_test_data(df_model=df_low_tst)[0], prep_test_data(df_model=df_low_tst)[1]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# lr_low[0].predict(df_low_tst_processed)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mlr_high\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep_test_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_high_tst\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsi-sg\\lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsi-sg\\lib\\site-packages\\sklearn\\linear_model\\_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    367\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsi-sg\\lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsi-sg\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 64 features, but LinearRegression is expecting 36 features as input."
     ]
    }
   ],
   "source": [
    "# df_low_tst_id, df_low_tst_processed = prep_test_data(df_model=df_low_tst)[0], prep_test_data(df_model=df_low_tst)[1]\n",
    "\n",
    "# lr_low[0].predict(df_low_tst_processed)\n",
    "lr_high[0].predict(prep_test_data(df_model=df_high_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f8d7a-53df-45c4-a66e-7f8af0d26697",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d29c82-ca36-4fa2-aea8-16dcd3075d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ohe = trn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea59493-d976-4141-88ae-324875aa8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ohe.drop([df_ohe.columns[i] for i in [0,1,2,4,6,13,14,15,17,18,19,23,42,43,56,59,60,62,63,64,75,76]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e24f96-bf68-419b-9a36-b45c70cc4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_num_cols = {k: v for k, v in zip(df_ohe.corr().sort_values('resale_price', ascending=False)['resale_price'].index, \n",
    "#                                       list(df_ohe.corr().sort_values('resale_price', ascending=False)['resale_price']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc2226-8281-4887-a4b9-9d86a6876f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols = list(corr_num_cols.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1198f7c-874f-4bc8-8f60-5e3c76a4e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df_ohe.columns:\n",
    "    \n",
    "#     if col not in num_cols:\n",
    "        \n",
    "#         df_dummy = pd.get_dummies(df_ohe[col], prefix=col)\n",
    "#         df_dummy['resale_price'] = df_ohe['resale_price']\n",
    "        \n",
    "#         col_name = df_dummy.corr().sort_values('resale_price', ascending=False)['resale_price'].index[1:]\n",
    "#         corr = list(df_dummy.corr().sort_values('resale_price', ascending=False)['resale_price'])[1:]\n",
    "\n",
    "#         for k, v in zip(col_name, corr):\n",
    "#             corr_num_cols[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298169a-19be-4479-b1e2-3ad612886056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in corr_num_cols.keys():\n",
    "#     corr_num_cols[col] = np.round(corr_num_cols[col], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061383e-438c-493a-b9f1-b92daee67c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del corr_num_cols['resale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc63fa-a318-4570-9ec6-08b37c4d5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corr = pd.DataFrame(corr_num_cols.values(), index=corr_num_cols.keys(), \n",
    "#                        columns=['correlation_with_resale_price']).sort_values('correlation_with_resale_price', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi-sg]",
   "language": "python",
   "name": "conda-env-dsi-sg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
